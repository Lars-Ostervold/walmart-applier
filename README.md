**NOTE âš ï¸** The README below is generated by AI. I'm just using this so I don't have to keep manually applying to relevant jobs. Making it public in case it helps others ğŸ™‚


---


# Walmart Job Application Automation

An automated system for discovering, evaluating, and applying to data science, data engineering, and data analytics roles at Walmart. The system uses AI to optimize resumes for specific job descriptions and automates the application process through Workday.

## Features

- **Job Discovery**: Automatically scrapes job listings from Walmart's career site
- **Relevance Checking**: Uses AI to evaluate job relevance based on your resume
- **Resume Optimization**: AI-powered resume editing to match job descriptions
- **PDF Generation**: Converts optimized resumes to ATS-friendly PDFs
- **Application Automation**: Automates the Workday application process
- **GitHub Actions Integration**: Scheduled and manual testing workflows
- **Error Handling**: Comprehensive logging and screenshot capture for debugging

## Prerequisites

- Python 3.9+
- Chrome/Chromium browser
- Pandoc
- LaTeX (for PDF generation)
- Google API Key (for Gemini AI)
- Workday credentials

## Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/walmart-applier.git
cd walmart-applier
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
# On Windows:
venv\Scripts\activate
# On Unix/MacOS:
source venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Install system dependencies:
```bash
# On Ubuntu/Debian:
sudo apt-get update
sudo apt-get install -y pandoc texlive-latex-base texlive-fonts-recommended texlive-extra-utils texlive-latex-extra

# On Windows:
# Install MiKTeX and Pandoc
```

5. Create a `.env` file with your credentials:
```
GOOGLE_API_KEY=your_google_api_key
WORKDAY_EMAIL=your_workday_email
WORKDAY_PASSWORD=your_workday_password
```

## Project Structure

```
walmart-applier/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ scheduled_pipeline.yml
â”‚       â””â”€â”€ test_pipeline.yml
â”œâ”€â”€ edited_resumes/
â”œâ”€â”€ generated_pdfs/
â”œâ”€â”€ main.py
â”œâ”€â”€ job_discovery.py
â”œâ”€â”€ job_filter.py
â”œâ”€â”€ job_details_scraper.py
â”œâ”€â”€ relevance_checker.py
â”œâ”€â”€ resume_editor.py
â”œâ”€â”€ pdf_generator.py
â”œâ”€â”€ application_submitter.py
â”œâ”€â”€ base_resume.md
â”œâ”€â”€ cv.md
â”œâ”€â”€ style.css
â””â”€â”€ requirements.txt
```

## Usage

### Local Development

1. Run the test pipeline with a single job:
```bash
python main.py --limit 1
```

2. Run the full pipeline:
```bash
python main.py
```

### GitHub Actions

The project includes two GitHub Actions workflows:

1. **Test Pipeline** (`test_pipeline.yml`):
   - Manually triggered
   - Processes one job
   - Uploads artifacts for inspection
   - Commits changes to `processed_jobs.json`

2. **Scheduled Pipeline** (`scheduled_pipeline.yml`):
   - Runs twice daily (12:00 PM and 5:00 PM CT)
   - Processes all available jobs
   - Uploads artifacts
   - Commits changes to `processed_jobs.json`

### Artifacts

After each run, the following artifacts are available in GitHub Actions:
- Generated PDFs
- Edited Markdown resumes
- Processed jobs log
- Error screenshots (if any)

## Configuration

### Resume Files

- `base_resume.md`: Your base resume in Markdown format
- `cv.md`: Your detailed CV for reference
- `style.css`: CSS styling for PDF generation

### Job Filtering

The system automatically filters jobs based on:
- Previous application status
- Relevance to your profile
- Required skills (excludes Java-heavy or big data roles)

## Error Handling

The system includes comprehensive error handling:
- Screenshots are captured on failures
- Detailed logging at each step
- Artifacts are preserved for debugging
- Failed jobs are marked for retry

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Uses Google's Gemini AI for resume optimization
- Selenium for web automation
- WeasyPrint for PDF generation
- GitHub Actions for automation 